---
title: 善用大语言模型服务
sidebar_position: 4
---
# 善用大语言模型服务
---
From: 东北大学-22-工业智能<br></br>
注: 本册中的年份标志均指大学本科入学时间

当下，以ChatGPT、文心一言、通义千问、DeepSeek为代表的大语言模型（LLM），正迅速融入我们的数字生活。你可以将它们理解为能力强大的“AI助手”或“智能聊天机器人”。它们功能多样，应用广泛，已成为许多人学习和工作的辅助工具。对于刚结束高考、即将步入大学或开始探索更广阔世界的你来说，接触并尝试这类工具是很自然的事。它们确实能协助写作、解答问题、整理信息，**但请务必记住：你才是主导者，而非工具本身。**

**有效利用的关键在于：明确其定位——它是辅助性的工具，而非全知全能的权威。** 我们需要清醒地认识它的**能力边界**：它能做什么？不能做什么？厘清使用中的责任归属至关重要。唯有如此，才能避免过度依赖，确保在使用中保持独立思考和判断力——如同驾驭任何工具，理性与清醒的态度是根本。

以ChatGPT这一代表性产品为例，顾名思义，它是用于对话的GPT模型。而“GPT（Generative Pre - Trained Transformer）是一种基于 Transformer 架构的生成式预训练语言模型。它首先将输入文本分割成称为 token 的小块并转换成向量，这些向量通过注意力机制和多层感知机等组件不断更新，以理解上下文并生成文本。模型的核心在于预测下一个词的概率分布，通过反复预测和采样生成文本。深度学习为 GPT 提供了大量可调参数，使其能够处理复杂任务并表现出色。”**简化来看：就是GPT是通过预测词的概率分布来生成文字，可以类比更复杂的完形填空，同时它每次的答案是随机的。**(https://www.3blue1brown.com/lessons/gpt)
由于用于训练模型的“文本”足够多足够广，模型在处理随机的“完形填空”任务时得分就相当高，当然它的分数也与任务类型相关([The Illusion of Thinking: Understanding the Strengths and Limitations of Reasoning Models via the Lens of Problem Complexity - Apple Machine Learning Research](https://machinelearning.apple.com/research/illusion-of-thinking))。但是和我们猜词一样，模型只能根据已有的范式推理出概率最高的结果，这意味着它不知道准确的最新的信息，也不能保证信息的准确度，更不能保证自身思路严谨。在市场竞争下，现在的大语言模型服务(及其变体)能够接受图片、文件、链接等(多模态)信息，不过基本原理也是将其转换为近似“完形填空”的形式生成(亦即选择高概率分布的词)结果。
在理解这类工具的原理后，我们已经进行了第一层祛魅。从应用的角度来看，前段时期deepseek r1模型刚发布时的《deepseek使用指南》就可以借鉴。同样的道理，**别让工具书或者博主的话弱化了你的思考能力。**在跳入“提示词工程/咒语编写”的漩涡之前，先审慎思考或试验你的目的能否通过较为简单自然的方式达到，让工具适应你而不是你去适应工具。(也有辅助提示词生成的工具如[PromptPilot · Streamlit --- PromptPilot · Streamlit](https://promptpilot.streamlit.app/))

